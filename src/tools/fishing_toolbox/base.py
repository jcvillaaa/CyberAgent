from langchain_core.tools import tool
from torch import argmax
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline

# Cargar modelos una sola vez
tokenizer_phishing = AutoTokenizer.from_pretrained("ealvaradob/bert-finetuned-phishing")
model_ealvaradob = AutoModelForSequenceClassification.from_pretrained("ealvaradob/bert-finetuned-phishing")
model_elslay = pipeline("text-classification", model="ElSlay/BERT-Phishing-Email-Model")


@tool
def phishing_ealvaradob(text: str) -> str:
    """Analiza si un texto es phishing usando el modelo BERT de ealvaradob.

    Args:
        text: Texto a analizar (email, URL, SMS o cualquier texto)

    Returns:
        AnÃ¡lisis de phishing con predicciÃ³n y nivel de confianza en formato legible
    """
    print("Usando herramienta phishing_ealvaradob")
    try:
        # Validar entrada
        if not text or not text.strip():
            return "âŒ Error: El texto no puede estar vacÃ­o"

        # Procesar con el modelo
        input_tokens = tokenizer_phishing(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        output = model_ealvaradob(**input_tokens)
        logits = output.logits
        probabilidades = logits.softmax(dim=1)
        prediccion_id = argmax(probabilidades, dim=1)

        # Extraer resultado
        pred_id = prediccion_id[0].item()
        etiqueta_predicha = model_ealvaradob.config.id2label[pred_id]
        prob_predicha = probabilidades[0, pred_id].item()

        # Determinar clasificaciÃ³n
        es_phishing = etiqueta_predicha == "phishing"
        clasificacion = "ğŸš¨ PHISHING" if es_phishing else "âœ… BENIGNO"
        confianza = prob_predicha * 100

        # Determinar nivel de riesgo
        if es_phishing:
            if confianza >= 90:
                nivel_riesgo = "MUY ALTO"
            elif confianza >= 70:
                nivel_riesgo = "ALTO"
            else:
                nivel_riesgo = "MODERADO"
        else:
            nivel_riesgo = "BAJO"

        resultado = f"""ğŸ” AnÃ¡lisis de Phishing (Modelo: ealvaradob/BERT)

                        ğŸ“Š Resultado: {clasificacion}
                        ğŸ¯ Confianza: {confianza:.1f}%
                        âš ï¸ Nivel de Riesgo: {nivel_riesgo}

                        ğŸ“ Texto analizado: "{text[:100]}{'...' if len(text) > 100 else ''}"
                    """

        return resultado

    except Exception as e:
        return f"âŒ Error al analizar con modelo ealvaradob: {str(e)}"


@tool
def phishing_elslay(text: str) -> str:
    """Analiza si un texto es phishing usando el modelo BERT de ElSlay.

    Args:
        text: Texto a analizar (email, URL, SMS o cualquier texto)

    Returns:
        AnÃ¡lisis de phishing con predicciÃ³n y nivel de confianza en formato legible
    """
    print("Usando herramienta phishing_elslay")
    try:
        # Validar entrada
        if not text or not text.strip():
            return "âŒ Error: El texto no puede estar vacÃ­o"

        # Procesar con el modelo
        resultado = model_elslay(text)

        if not resultado or len(resultado) == 0:
            return "âŒ Error: No se pudo procesar el texto"

        # Extraer resultado (tomar el primer resultado si hay mÃºltiples)
        pred_info = resultado[0]
        pred_id = pred_info["label"]
        prob_predicha = pred_info["score"]

        # Determinar clasificaciÃ³n
        es_phishing = pred_id == "LABEL_1"
        clasificacion = "ğŸš¨ PHISHING" if es_phishing else "âœ… BENIGNO"
        confianza = prob_predicha * 100

        # Determinar nivel de riesgo
        if es_phishing:
            if confianza >= 90:
                nivel_riesgo = "MUY ALTO"
            elif confianza >= 70:
                nivel_riesgo = "ALTO"
            else:
                nivel_riesgo = "MODERADO"
        else:
            nivel_riesgo = "BAJO"

        resultado_formateado = f"""ğŸ” AnÃ¡lisis de Phishing (Modelo: ElSlay/BERT)

ğŸ“Š Resultado: {clasificacion}
ğŸ¯ Confianza: {confianza:.1f}%
âš ï¸ Nivel de Riesgo: {nivel_riesgo}

ğŸ“ Texto analizado: "{text[:100]}{'...' if len(text) > 100 else ''}"
"""

        return resultado_formateado

    except Exception as e:
        return f"âŒ Error al analizar con modelo ElSlay: {str(e)}"


@tool
def phishing_analysis_comparison(text: str) -> str:
    """Realiza un anÃ¡lisis comparativo de phishing usando ambos modelos BERT.

    Args:
        text: Texto a analizar (email, URL, SMS o cualquier texto)

    Returns:
        AnÃ¡lisis comparativo con recomendaciones basadas en ambos modelos
    """
    print("Usando herramienta phishing_analysis_comparison")
    try:
        # Validar entrada
        if not text or not text.strip():
            return "âŒ Error: El texto no puede estar vacÃ­o"

        # AnÃ¡lisis con modelo ealvaradob
        try:
            input_tokens = tokenizer_phishing(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
            output1 = model_ealvaradob(**input_tokens)
            logits1 = output1.logits
            prob1 = logits1.softmax(dim=1)
            pred1_id = argmax(prob1, dim=1)[0].item()
            etiqueta1 = model_ealvaradob.config.id2label[pred1_id]
            confianza1 = prob1[0, pred1_id].item() * 100
            es_phishing1 = etiqueta1 == "phishing"
        except Exception as e:
            return f"âŒ Error en modelo ealvaradob: {str(e)}"

        # AnÃ¡lisis con modelo ElSlay
        try:
            resultado2 = model_elslay(text)
            pred2_info = resultado2[0]
            es_phishing2 = pred2_info["label"] == "LABEL_1"
            confianza2 = pred2_info["score"] * 100
        except Exception as e:
            return f"âŒ Error en modelo ElSlay: {str(e)}"

        # AnÃ¡lisis comparativo
        ambos_detectan = es_phishing1 and es_phishing2
        ninguno_detecta = not es_phishing1 and not es_phishing2
        #discrepancia = es_phishing1 != es_phishing2

        # Determinar recomendaciÃ³n final
        if ambos_detectan:
            if confianza1 >= 70 and confianza2 >= 70:
                recomendacion = "ğŸš¨ ALTO RIESGO - Ambos modelos detectan phishing con alta confianza"
                nivel_final = "CRÃTICO"
            else:
                recomendacion = "âš ï¸ RIESGO MODERADO - Ambos modelos detectan phishing"
                nivel_final = "ALTO"
        elif ninguno_detecta:
            if confianza1 >= 70 and confianza2 >= 70:
                recomendacion = "âœ… BAJO RIESGO - Ambos modelos clasifican como benigno"
                nivel_final = "BAJO"
            else:
                recomendacion = "ğŸ¤” REVISAR - Baja confianza en ambos modelos"
                nivel_final = "INCIERTO"
        else:
            recomendacion = "âš ï¸ DISCREPANCIA - Los modelos no coinciden, revisar manualmente"
            nivel_final = "MODERADO"

        resultado_final = f"""ğŸ” AnÃ¡lisis Comparativo de Phishing

ğŸ“Š MODELO EALVARADOB:
   â€¢ Resultado: {'ğŸš¨ PHISHING' if es_phishing1 else 'âœ… BENIGNO'}
   â€¢ Confianza: {confianza1:.1f}%

ğŸ“Š MODELO ELSLAY:
   â€¢ Resultado: {'ğŸš¨ PHISHING' if es_phishing2 else 'âœ… BENIGNO'}
   â€¢ Confianza: {confianza2:.1f}%

ğŸ¯ ANÃLISIS FINAL:
   â€¢ Nivel de Riesgo: {nivel_final}
   â€¢ RecomendaciÃ³n: {recomendacion}

ğŸ“ Texto analizado: "{text[:100]}{'...' if len(text) > 100 else ''}"
"""

        return resultado_final

    except Exception as e:
        return f"âŒ Error en anÃ¡lisis comparativo: {str(e)}"
